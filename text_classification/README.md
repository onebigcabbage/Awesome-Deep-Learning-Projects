## Text Classification



### Feature Extraction

- #### BOW

  每个文档转化为一个向量，向量的长度为所有文档中全部不同的词，向量的每一位则代表该词出现频率。

  优点是计算快，表述简单。

  缺点是只考虑到了词的频率，没有考虑词的特性。

  改进：加入 ***n-gram*** 模型。

- #### TF-IDF

  词袋模型中严重依赖词的频率，频率高的词会影响频率不高但是更有意义的词。

  *TF-IDF* 由 $tf​$ (词频) * $idf​$ (逆文档频率) 组成，刚好弥补了 *BOW* 的缺点。

  $tf(w, D) = \frac{n_w}{N}$ 表示词 $w$ 在文档 $D$ 中所有不同的词里出现的频率 ，

  $idf(w) = 1 + log \frac{N}{1 + N(w)}$ 是使用文档总数除以包括词 $w$ 的文档数量，对结果用对数运算，加 1 是为了避免文档中没有某个生僻词使得分母为 0。

- #### Word2Vec



---



### Model

- #### 朴素贝叶斯

- #### SVM

---



---



### Others

后期会添加其他模型。

供大家参考，欢迎给个 **star** 或 **fork**  。

