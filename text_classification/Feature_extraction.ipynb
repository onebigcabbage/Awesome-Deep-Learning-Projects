{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'the sky is blue',\n",
    "    'sky is blue and sky is beautiful',\n",
    "    'the beautiful is so blue',\n",
    "    'i love blue cheese'\n",
    "]\n",
    "\n",
    "doc = ['loving this blue sky today']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_extract(corpus, ngrams=(1, 1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngrams)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_features(fea_names, features):\n",
    "    df = pd.DataFrame(data=features, columns=fea_names)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'beautiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so', 'the']\n",
      "[[0 0 1 0 1 0 1 0 1]\n",
      " [1 1 1 0 2 0 2 0 0]\n",
      " [0 1 1 0 1 0 0 1 1]\n",
      " [0 0 1 1 0 1 0 0 0]]\n",
      "   and  beautiful  blue  cheese  is  love  sky  so  the\n",
      "0    0          0     1       0   1     0    1   0    1\n",
      "1    1          1     1       0   2     0    2   0    0\n",
      "2    0          1     1       0   1     0    0   1    1\n",
      "3    0          0     1       1   0     1    0   0    0\n"
     ]
    }
   ],
   "source": [
    "bow_vectorizer, bow_features = bow_extract(corpus)\n",
    "\n",
    "fea_names = bow_vectorizer.get_feature_names()\n",
    "bow_features = bow_features.todense()\n",
    "\n",
    "print(fea_names)\n",
    "print(bow_features)\n",
    "\n",
    "display_features(fea_names, bow_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  beautiful  blue  cheese  is  love  sky  so  the\n",
      "0    0          0     1       0   0     0    1   0    0\n"
     ]
    }
   ],
   "source": [
    "# transform new doc to vector of bow model\n",
    "doc_features = bow_vectorizer.transform(doc).todense()\n",
    "\n",
    "display_features(fea_names, doc_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF\n",
    "### 基于词袋模型的词进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_extract(bow_features):\n",
    "    transformer = TfidfTransformer(norm='l2', smooth_idf=True, use_idf=True)\n",
    "    tfidf_features = transformer.fit_transform(bow_features)\n",
    "    return transformer, tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.5685556582078485\n",
      "  (0, 6)\t0.5685556582078485\n",
      "  (0, 4)\t0.4602948056749725\n",
      "  (0, 2)\t0.37632116457664155\n",
      "  (1, 6)\t0.6432036103096459\n",
      "  (1, 4)\t0.5207287563545564\n",
      "  (1, 2)\t0.21286493960380123\n",
      "  (1, 1)\t0.32160180515482295\n",
      "  (1, 0)\t0.40791111090371607\n",
      "  (2, 8)\t0.46115286047158355\n",
      "  (2, 7)\t0.5849139295745928\n",
      "  (2, 4)\t0.37334298451327075\n",
      "  (2, 2)\t0.3052323532361606\n",
      "  (2, 1)\t0.46115286047158355\n",
      "  (3, 5)\t0.6633846138519129\n",
      "  (3, 3)\t0.6633846138519129\n",
      "  (3, 2)\t0.34618161159873423\n",
      "[[0.   0.   0.38 0.   0.46 0.   0.57 0.   0.57]\n",
      " [0.41 0.32 0.21 0.   0.52 0.   0.64 0.   0.  ]\n",
      " [0.   0.46 0.31 0.   0.37 0.   0.   0.58 0.46]\n",
      " [0.   0.   0.35 0.66 0.   0.66 0.   0.   0.  ]]\n",
      "    and  beautiful  blue  cheese    is  love   sky    so   the\n",
      "0  0.00       0.00  0.38    0.00  0.46  0.00  0.57  0.00  0.57\n",
      "1  0.41       0.32  0.21    0.00  0.52  0.00  0.64  0.00  0.00\n",
      "2  0.00       0.46  0.31    0.00  0.37  0.00  0.00  0.58  0.46\n",
      "3  0.00       0.00  0.35    0.66  0.00  0.66  0.00  0.00  0.00\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer, tfidf_features = tfidf_extract(bow_features)\n",
    "\n",
    "print(tfidf_features)\n",
    "\n",
    "tfidf_features = np.round(tfidf_features.todense(), 2)\n",
    "print(tfidf_features)\n",
    "\n",
    "display_features(fea_names, tfidf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  beautiful  blue  cheese   is  love   sky   so  the\n",
      "0  0.0        0.0  0.55     0.0  0.0   0.0  0.83  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# transform new doc to vector of bow model\n",
    "doc_tfidf_features = tfidf_transformer.transform(doc_features)\n",
    "doc_tfidf_features = np.round(doc_tfidf_features.todense(), 2)\n",
    "\n",
    "display_features(fea_names, doc_tfidf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF - 2\n",
    "### 直接计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_extract2(corpus, ngrams=(1, 1)):\n",
    "    vectorizer = TfidfVectorizer(min_df=1, ngram_range=ngrams, norm='l2', smooth_idf=True, use_idf=True)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    and  beautiful  blue  cheese    is  love   sky    so   the\n",
      "0  0.00       0.00  0.38    0.00  0.46  0.00  0.57  0.00  0.57\n",
      "1  0.41       0.32  0.21    0.00  0.52  0.00  0.64  0.00  0.00\n",
      "2  0.00       0.46  0.31    0.00  0.37  0.00  0.00  0.58  0.46\n",
      "3  0.00       0.00  0.35    0.66  0.00  0.66  0.00  0.00  0.00\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer, tfidf_features = tfidf_extract2(corpus)\n",
    "\n",
    "display_features(fea_names, np.round(tfidf_features.todense(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  beautiful  blue  cheese   is  love   sky   so  the\n",
      "0  0.0        0.0  0.55     0.0  0.0   0.0  0.83  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# transform new doc to vector of bow model\n",
    "doc_tfidf_features = tfidf_vectorizer.transform(doc)\n",
    "\n",
    "display_features(fea_names, np.round(doc_tfidf_features.todense(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Applications\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.word_tokenize(sen) for sen in corpus]\n",
    "docs = [nltk.word_tokenize(sen) for sen in doc]\n",
    "\n",
    "model = Word2Vec(sentences, size=10, window=10, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04478759  0.04840298 -0.02347958  0.00326061 -0.02830264  0.01282009\n",
      " -0.00129597  0.04345105  0.03344116  0.02269522]\n",
      "[('is', 0.064363032579422), ('the', -0.11029154062271118), ('beautiful', -0.1127469539642334), ('sky', -0.11970236897468567)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['sky'])\n",
    "print(model.wv.most_similar('blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stored in a KeyedVectors instance\n",
    "word_vec = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04805895 -0.04145954  0.0315539  -0.01477276  0.04520844 -0.04808239\n",
      " -0.00829656  0.02893448 -0.02975751 -0.04921004]\n"
     ]
    }
   ],
   "source": [
    "print(word_vec['sky'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load model\n",
    "model.save(filename)\n",
    "model = Word2Vec.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句子向量\n",
    "### 平均词向量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_words_vector(sen, model, vocabulary, ndims):\n",
    "    feature = np.zeros((ndims,), dtype=\"float64\")\n",
    "    word_count = 0\n",
    "    \n",
    "    for word in sen.split():\n",
    "        if word in vocabulary:\n",
    "            feature = np.add(feature, model.wv[word])\n",
    "            word_count = word_count + 1\n",
    "            \n",
    "    feature = np.divide(feature, word_count)\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_feature(corpus, model, ndims=10):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_words_vector(sen, model, vocabulary, ndims) for sen in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.016 -0.    -0.004  0.014 -0.014  0.019  0.     0.022  0.029 -0.005]\n",
      " [-0.018  0.002 -0.013  0.007  0.003  0.003  0.007  0.011  0.03   0.007]\n",
      " [-0.01  -0.016 -0.008  0.013  0.004  0.012  0.002 -0.001  0.016  0.001]\n",
      " [ 0.003 -0.009 -0.023  0.015 -0.002  0.034  0.018 -0.035  0.035 -0.05 ]]\n"
     ]
    }
   ],
   "source": [
    "sen_feature = get_sentence_feature(corpus, model)\n",
    "print(np.round(sen_feature, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF加权平均词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
