{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两个句子的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2, stopword):\n",
    "    \n",
    "    sent1 = [w.lower() for w in sent1 if w not in stopword]\n",
    "    sent2 = [w.lower() for w in sent2 if w not in stopword]\n",
    "    \n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "        \n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算句子-句子相似矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences, stopword):\n",
    "    \n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stopword)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手动计算每个句子的 PageRank 值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_pagerank(similarity_matrix):\n",
    "    \n",
    "    new_scores = [0.5 for _ in range(len(similarity_matrix))]\n",
    "    old_scores = [0.0 for _ in range(len(similarity_matrix))]\n",
    "    \n",
    "    while isUpdate(new_scores, old_scores):\n",
    "        for i in range(len(similarity_matrix)):\n",
    "            old_scores[i] = new_scores[i]\n",
    "        for i in range(len(similarity_matrix)):\n",
    "            new_scores[i] = update_score(similarity_matrix, new_scores, i)\n",
    "    return new_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "若更新后的分数和更新前的分数相差小于0.0001，则认为 PR 值已趋于稳定\n",
    "\"\"\"\n",
    "def isUpdate(new_scores, old_scores):\n",
    "    flag = False\n",
    "    for i in range(len(new_scores)):\n",
    "        if math.fabs(new_scores[i] - old_scores[i]) >= 0.0001:\n",
    "            flag = True\n",
    "            break\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_score(weight_graph, scores, i):\n",
    "    length = len(weight_graph)\n",
    "    d = 0.85\n",
    "    added_score = 0.0\n",
    " \n",
    "    for j in range(length):\n",
    "        fraction = 0.0\n",
    "        denominator = 0.0\n",
    "        # 计算分子\n",
    "        fraction = weight_graph[j][i] * scores[j]\n",
    "        # 计算分母\n",
    "        for k in range(length):\n",
    "            denominator += weight_graph[j][k]\n",
    "        added_score += fraction / denominator\n",
    "    weighted_score = (1 - d) + d * added_score\n",
    " \n",
    "    return weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(file_name, top_n=5):\n",
    "    \n",
    "    stopword = set(stopwords.words('english') + list(punctuation))\n",
    "    \n",
    "    data = open(file_name, \"r\").read().replace('\\n', ' ')\n",
    "    \n",
    "    # 切分句子\n",
    "    article = data.split('. ')\n",
    "    sentences = []\n",
    "    \n",
    "    for sen in article:\n",
    "        sentences.append(sen.split(\" \"))\n",
    "        \n",
    "    # 句子转化为向量，并计算相似度\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences, stopword)\n",
    "    \n",
    "    ############################################################\n",
    "    #\n",
    "    # 1. 手动计算每个句子的 PageRank 值\n",
    "    #\n",
    "    scores = sentences_pagerank(sentence_similarity_matrix)\n",
    "    # print(scores)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "    #\n",
    "    # 2. 使用复杂网络库networkx计算图中每个节点的 PageRank 值\n",
    "    #\n",
    "    \n",
    "    # 根据句子间的相似度，构建相似矩阵图\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "    # print(sentence_similarity_graph.edges(data=True))\n",
    "    \n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # 根据 PR 值对句子排序\n",
    "    ranked_sentence = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    # print(ranked_sentence)\n",
    "    \n",
    "    # 选取 PR 值最高的 top_n 个句子组成摘要\n",
    "    summarize_text = []\n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "        \n",
    "    print(\"Summarize: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize: \n",
      " You can read more about installing beta software on iOS and Apple TV devices on Apple's support page. The new 12.3 betas include the new Apple TV app which is scheduled to officially launch in May. Apple has released the first beta of iOS 12.3 and tvOS 12.3 to developers. The developments comes just a few days since it released iOS 12.2 which came with support for Apple News+ and new Animoji. For those of you with Apple's third-generation set-top box, the firm has released a beta version of Apple TV Software 7.3 which can be downloaded and installed via iTunes\n"
     ]
    }
   ],
   "source": [
    "generate_summary(\"./data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
